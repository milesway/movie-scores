{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import \n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, confusion_matrix\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from textblob import TextBlob\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish loading\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "trainingSet = pd.read_csv(\"train.csv\")\n",
    "testingSet = pd.read_csv(\"test.csv\")\n",
    "print(\"finish loading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatization text by removing stopwords \n",
    "def lemmatization(text):\n",
    "    stopWord = stopwords.words('english')\n",
    "    # init Lemmatizer\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    # remove non charaters\n",
    "    text = re.sub(r'[^a-zA-Z]', ' ', str(text))\n",
    "    # change all charaters to lower case\n",
    "    words = text.lower().split()\n",
    "    # run lemmatizer\n",
    "    words = [lemmatizer.lemmatize(w) for w in words if w not in stopWord]\n",
    "    return ' '.join(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finsih lemmatization, see detail below:\n"
     ]
    }
   ],
   "source": [
    "# Adding new column of clean_review\n",
    "trainingSet['clean_review'] = [lemmatization(text) for text in trainingSet.Text]\n",
    "print(\"finsih lemmatization, see detail below:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Id   ProductId          UserId  HelpfulnessNumerator  \\\n",
      "0              0  0005019281   ADZPIG9QOCDG5                     0   \n",
      "1              1  0005019281  A35947ZP82G7JH                     0   \n",
      "2              2  0005019281  A3UORV8A9D5L2E                     0   \n",
      "3              3  0005019281  A1VKW06X1O2X7V                     0   \n",
      "4              4  0005019281  A3R27T4HADWFFJ                     0   \n",
      "...          ...         ...             ...                   ...   \n",
      "1697528  1697528  B00LT1JHLW   AV657BUYHHXZ2                     1   \n",
      "1697529  1697529  B00LT1JHLW  A17W587EH23J0Q                    32   \n",
      "1697530  1697530  B00LT1JHLW  A3DE438TF1A958                     3   \n",
      "1697531  1697531  B00LT1JHLW  A2RWCXDMANY0LW                     0   \n",
      "1697532  1697532  B00LT1JHLW  A3ROPC55BE2OM9                    11   \n",
      "\n",
      "         HelpfulnessDenominator  Score        Time  \\\n",
      "0                             0    4.0  1203984000   \n",
      "1                             0    3.0  1388361600   \n",
      "2                             0    3.0  1388361600   \n",
      "3                             0    5.0  1202860800   \n",
      "4                             0    4.0  1387670400   \n",
      "...                         ...    ...         ...   \n",
      "1697528                      14    NaN  1406073600   \n",
      "1697529                      48    5.0  1405641600   \n",
      "1697530                      10    5.0  1405728000   \n",
      "1697531                       4    5.0  1405987200   \n",
      "1697532                      23    5.0  1405728000   \n",
      "\n",
      "                                                   Summary  \\\n",
      "0                                good version of a classic   \n",
      "1                                   Good but not as moving   \n",
      "2                    Winkler's Performance was ok at best!   \n",
      "3             It's an enjoyable twist on the classic story   \n",
      "4                                         Best Scrooge yet   \n",
      "...                                                    ...   \n",
      "1697528                      Way to Expensive!! WB = GREED   \n",
      "1697529  HOLY BAT-BOXSET, BATMAN... I never thought thi...   \n",
      "1697530  prayers have been answered because batman 60s ...   \n",
      "1697531                                        can't Wait!   \n",
      "1697532  The Price is Insane? People Really Need to Wak...   \n",
      "\n",
      "                                                      Text  \\\n",
      "0        This is a charming version of the classic Dick...   \n",
      "1        It was good but not as emotionally moving as t...   \n",
      "2        Don't get me wrong, Winkler is a wonderful cha...   \n",
      "3        Henry Winkler is very good in this twist on th...   \n",
      "4        This is one of the best Scrooge movies out.  H...   \n",
      "...                                                    ...   \n",
      "1697528  wow $269.99 for the entire series on Blu Ray??...   \n",
      "1697529  Finally, the holy grail of tv-on-dvd boxsets i...   \n",
      "1697530  Could this be a true or I'm i dreaming batman ...   \n",
      "1697531  I've been a fan of the series since I was a yo...   \n",
      "1697532  People seriously need to wake up and realize t...   \n",
      "\n",
      "                                              clean_review  \n",
      "0        charming version classic dicken tale henry win...  \n",
      "1        good emotionally moving christmas carol dicken...  \n",
      "2        get wrong winkler wonderful character actor wo...  \n",
      "3        henry winkler good twist classic story convent...  \n",
      "4        one best scrooge movie henry winkler outdoes c...  \n",
      "...                                                    ...  \n",
      "1697528  wow entire series blu ray thats per season get...  \n",
      "1697529  finally holy grail tv dvd boxsets coming blu r...  \n",
      "1697530  could true dreaming batman favorite comic book...  \n",
      "1697531  fan series since young boy personaly consider ...  \n",
      "1697532  people seriously need wake realize get blu ray...  \n",
      "\n",
      "[1697533 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "print(trainingSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate sentiment score\n",
    "# Objective if close to 0\n",
    "def polarity(text):\n",
    "    textblob = TextBlob(text)\n",
    "    return round(textblob.polarity,3)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding new column of clean_review\n",
    "trainingSet['polarity'] = [polarity(text) for text in trainingSet.lemma_review]\n",
    "print(\"finish calculate polarity, see detail below:\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainingSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create x_text and x_train\n",
    "X_test = pd.merge(trainingSet, testingSet, left_on='Id', right_on='Id')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Id   ProductId          UserId  HelpfulnessNumerator  \\\n",
      "0             5  0005019281  A2L0G56BNOTX6S                     0   \n",
      "1            11  0005019281  A33EWPXESP9GQH                     0   \n",
      "2            17  0005019281  A13KAQO9F5X0FN                     0   \n",
      "3            46  0005019281  A306NASGVUDFKF                    10   \n",
      "4            47  0005019281  A38G1NN5SD81GD                     0   \n",
      "...         ...         ...             ...                   ...   \n",
      "299995  1697520  B00LH9ROKM   AYB0IXBPBJ20A                     0   \n",
      "299996  1697522  B00LT1JHLW   AU73NIGESSIRE                    25   \n",
      "299997  1697524  B00LT1JHLW  A3PPYOJBMFBP6U                     3   \n",
      "299998  1697527  B00LT1JHLW  A2CA2Q6JS6CQAE                    10   \n",
      "299999  1697528  B00LT1JHLW   AV657BUYHHXZ2                     1   \n",
      "\n",
      "        HelpfulnessDenominator  Score_x        Time  \\\n",
      "0                            0      NaN  1383696000   \n",
      "1                            0      NaN  1390780800   \n",
      "2                            0      NaN  1389657600   \n",
      "3                           14      NaN  1132963200   \n",
      "4                            1      NaN  1384905600   \n",
      "...                        ...      ...         ...   \n",
      "299995                       1      NaN  1404345600   \n",
      "299996                      88      NaN  1405555200   \n",
      "299997                      10      NaN  1405728000   \n",
      "299998                      14      NaN  1405987200   \n",
      "299999                      14      NaN  1406073600   \n",
      "\n",
      "                                                  Summary  \\\n",
      "0                                        Dickens updated.   \n",
      "1                                            Good Version   \n",
      "2                                   the fonz does scrooge   \n",
      "3                 A refreshing twist on a Holiday classic   \n",
      "4                                         Not my favorite   \n",
      "...                                                   ...   \n",
      "299995  Basically an Episode of Criminal Minds, See It...   \n",
      "299996  July 17, 2014 - the first day of pre-order (wi...   \n",
      "299997  Please Include The 'Batman In Color' Bumper Wh...   \n",
      "299998    Finally on dvd and blu-ray The Batman TV Series   \n",
      "299999                      Way to Expensive!! WB = GREED   \n",
      "\n",
      "                                                     Text  \\\n",
      "0       This has been a favorite movie of mine for a l...   \n",
      "1       Even though i don't care for Henry Winklers  a...   \n",
      "2       Anorher good movie for holiday watchers..a lit...   \n",
      "3       My wife and I grew up in New Hampshire where t...   \n",
      "4       This is a first for me, I didn't like this mov...   \n",
      "...                                                   ...   \n",
      "299995  Just how seriously one should take Scott Derri...   \n",
      "299996  Let's be clear - the 5 stars are for the serie...   \n",
      "299997  I would also like to see the original 20th Cen...   \n",
      "299998  Finally to be released on DVD and Blu-Ray Nove...   \n",
      "299999  wow $269.99 for the entire series on Blu Ray??...   \n",
      "\n",
      "                                             clean_review  Score_y  \n",
      "0       favorite movie mine long time henry winkler gr...      NaN  \n",
      "1       even though care henry winklers acting liked m...      NaN  \n",
      "2       anorher good movie holiday watcher little twis...      NaN  \n",
      "3       wife grew new hampshire version take place eas...      NaN  \n",
      "4                    first like movie think minute acting      NaN  \n",
      "...                                                   ...      ...  \n",
      "299995  seriously one take scott derrickson latest cra...      NaN  \n",
      "299996  let clear star series product review july firs...      NaN  \n",
      "299997  would also like see original th century fox se...      NaN  \n",
      "299998  finally released dvd blu ray november episode ...      NaN  \n",
      "299999  wow entire series blu ray thats per season get...      NaN  \n",
      "\n",
      "[300000 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish X_train and X_submission split\n"
     ]
    }
   ],
   "source": [
    "# Code provided in generate-Xtrain-Xsubmission.py\n",
    "X_test = X_test.drop(columns=['Score_x'])\n",
    "X_test = X_test.rename(columns={'Score_y': 'Score'})\n",
    "\n",
    "X_test.to_csv(\"X_submission.csv\", index=False)\n",
    "\n",
    "X_train = trainingSet[trainingSet['Score'].notnull()]\n",
    "\n",
    "\n",
    "X_train.to_csv(\"X_train.csv\", index=False)\n",
    "print(\"finish X_train and X_submission split\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              Id   ProductId          UserId  HelpfulnessNumerator  \\\n",
      "0              0  0005019281   ADZPIG9QOCDG5                     0   \n",
      "1              1  0005019281  A35947ZP82G7JH                     0   \n",
      "2              2  0005019281  A3UORV8A9D5L2E                     0   \n",
      "3              3  0005019281  A1VKW06X1O2X7V                     0   \n",
      "4              4  0005019281  A3R27T4HADWFFJ                     0   \n",
      "...          ...         ...             ...                   ...   \n",
      "1697526  1697526  B00LT1JHLW  A22OB0DIJ5FO0G                     2   \n",
      "1697529  1697529  B00LT1JHLW  A17W587EH23J0Q                    32   \n",
      "1697530  1697530  B00LT1JHLW  A3DE438TF1A958                     3   \n",
      "1697531  1697531  B00LT1JHLW  A2RWCXDMANY0LW                     0   \n",
      "1697532  1697532  B00LT1JHLW  A3ROPC55BE2OM9                    11   \n",
      "\n",
      "         HelpfulnessDenominator  Score        Time  \\\n",
      "0                             0    4.0  1203984000   \n",
      "1                             0    3.0  1388361600   \n",
      "2                             0    3.0  1388361600   \n",
      "3                             0    5.0  1202860800   \n",
      "4                             0    4.0  1387670400   \n",
      "...                         ...    ...         ...   \n",
      "1697526                      12    4.0  1405728000   \n",
      "1697529                      48    5.0  1405641600   \n",
      "1697530                      10    5.0  1405728000   \n",
      "1697531                       4    5.0  1405987200   \n",
      "1697532                      23    5.0  1405728000   \n",
      "\n",
      "                                                   Summary  \\\n",
      "0                                good version of a classic   \n",
      "1                                   Good but not as moving   \n",
      "2                    Winkler's Performance was ok at best!   \n",
      "3             It's an enjoyable twist on the classic story   \n",
      "4                                         Best Scrooge yet   \n",
      "...                                                    ...   \n",
      "1697526   Worth the wait, but worth the asking price, too?   \n",
      "1697529  HOLY BAT-BOXSET, BATMAN... I never thought thi...   \n",
      "1697530  prayers have been answered because batman 60s ...   \n",
      "1697531                                        can't Wait!   \n",
      "1697532  The Price is Insane? People Really Need to Wak...   \n",
      "\n",
      "                                                      Text  \\\n",
      "0        This is a charming version of the classic Dick...   \n",
      "1        It was good but not as emotionally moving as t...   \n",
      "2        Don't get me wrong, Winkler is a wonderful cha...   \n",
      "3        Henry Winkler is very good in this twist on th...   \n",
      "4        This is one of the best Scrooge movies out.  H...   \n",
      "...                                                    ...   \n",
      "1697526  Looking very much forward to this release, but...   \n",
      "1697529  Finally, the holy grail of tv-on-dvd boxsets i...   \n",
      "1697530  Could this be a true or I'm i dreaming batman ...   \n",
      "1697531  I've been a fan of the series since I was a yo...   \n",
      "1697532  People seriously need to wake up and realize t...   \n",
      "\n",
      "                                              clean_review  \n",
      "0        charming version classic dicken tale henry win...  \n",
      "1        good emotionally moving christmas carol dicken...  \n",
      "2        get wrong winkler wonderful character actor wo...  \n",
      "3        henry winkler good twist classic story convent...  \n",
      "4        one best scrooge movie henry winkler outdoes c...  \n",
      "...                                                    ...  \n",
      "1697526  looking much forward release price bit outrage...  \n",
      "1697529  finally holy grail tv dvd boxsets coming blu r...  \n",
      "1697530  could true dreaming batman favorite comic book...  \n",
      "1697531  fan series since young boy personaly consider ...  \n",
      "1697532  people seriously need wake realize get blu ray...  \n",
      "\n",
      "[1397533 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read from file\n",
    "X_train = pd.read_csv(\"X_train.csv\")\n",
    "X_submission = pd.read_csv(\"X_submission.csv\")\n",
    "\n",
    "# Split training set into training and testing set\n",
    "# Code provided in predict-knn.py\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(\n",
    "        X_train.drop(['Score'], axis=1),\n",
    "        X_train['Score'],\n",
    "        test_size=1/4.0,\n",
    "        random_state=0\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train['clean_review'] = X_train['clean_review'].fillna(\"n\")\n",
    "X_test['clean_review'] = X_test['clean_review'].fillna(\"n\")\n",
    "X_submission['clean_review'] = X_submission['clean_review'].fillna(\"n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(X_train['clean_review'].isnull().sum())\n",
    "print(X_test['clean_review'].isnull().sum())\n",
    "print(X_submission['clean_review'].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Vectorlize clean_review only \n",
    "# inti by setting feature number\n",
    "vectorizer = CountVectorizer(max_features = 5000) \n",
    "\n",
    "# Vectorlize X_train, X_test and X_Submission\n",
    "vector_train = vectorizer.fit_transform(X_train.clean_review).toarray()\n",
    "vector_test = vectorizer.transform(X_test.clean_review).toarray()\n",
    "vector_submit = vectorizer.transform(X_submission.clean_review).toarray()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process the DataFrames\n",
    "# This is where you can do more feature extraction\n",
    "X_train_processed = X_train.drop(columns=['Id', 'ProductId', 'UserId', 'Text', 'Summary', 'clean_review'])\n",
    "X_test_processed = X_test.drop(columns=['Id', 'ProductId', 'UserId', 'Text', 'Summary','clean_review'])\n",
    "X_submission_processed = X_submission.drop(columns=['Id', 'ProductId', 'UserId', 'Text', 'Summary', 'Score','clean_review'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learn the review model\n",
    "# Create random forest model\n",
    "forestor = RandomForestClassifier(n_estimators = 100,n_jobs=8)\n",
    "# Set Grid Search parameters\n",
    "n_estimators = [100]\n",
    "min_samples_split = [2]\n",
    "min_samples_leaf = [1]\n",
    "bootstrap = [True]\n",
    "parameters = {'n_estimators': n_estimators, 'min_samples_leaf': min_samples_leaf,'min_samples_split': min_samples_split}\n",
    "# Apply Grid search \n",
    "clf = GridSearchCV(forestor, param_grid=parameters)\n",
    "# Fit data to creat model\n",
    "model_vector = clf.fit(vector_train, Y_train)\n",
    "print(\"finish model_review\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish model\n"
     ]
    }
   ],
   "source": [
    "# Learn the review model\n",
    "#create random forest model\n",
    "forestor2 = RandomForestClassifier(n_estimators = 100,n_jobs=8)\n",
    "# Set Grid Search parameters\n",
    "n_estimators = [100]\n",
    "min_samples_split = [2]\n",
    "min_samples_leaf = [1]\n",
    "bootstrap = [True]\n",
    "parameters = {'n_estimators': n_estimators, 'min_samples_leaf': min_samples_leaf,'min_samples_split': min_samples_split}\n",
    "# Apply Grid search \n",
    "clf2 = GridSearchCV(forestor2, param_grid=parameters)\n",
    "# Fit data to creat model\n",
    "model = clf2.fit(X_train_processed, Y_train)\n",
    "print(\"finish model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict using vector\n",
    "Y_test1 = model_vector.predict(vector_test)\n",
    "X_submission['Score1'] = model_vector.predict(vector_submit)\n",
    "\n",
    "# Predict using regular pd\n",
    "Y_test2 = model.predict(X_test_processed)\n",
    "X_submission['Score2'] = model.predict(X_submission_processed)\n",
    "\n",
    "# Combine two methods together with different weight\n",
    "Y_av = (Y_test1 * 0.7 + Y_test2 * 0.3).round(0)\n",
    "X_submission['Score']=(X_submission['Score1']*0.7+X_submission['Score2']*0.3).round(0)\n",
    "\n",
    "\n",
    "# Evaluate your model on the testing set\n",
    "print(\"RMSE on testing set: review predict = \", mean_squared_error(Y_test, Y_test1))\n",
    "print(\"RMSE on testing set: regular predict = \", mean_squared_error(Y_test, Y_test2))\n",
    "print(\"RMSE on testing set: regular predict = \", mean_squared_error(Y_test, Y_av))\n",
    "\n",
    "# Create the submission file\n",
    "submission = X_submission[['Id', 'Score1']]\n",
    "submission.to_csv(\"submission1.csv\", index=False)\n",
    "\n",
    "submission = X_submission[['Id', 'Score2']]\n",
    "submission.to_csv(\"submission2.csv\", index=False)\n",
    "\n",
    "submission = X_submission[['Id', 'Score']]\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_av4 = (Y_test_review_pre * 0.6 + Y_test_regular_pre * 0.4).round(0)\n",
    "X_submission['Score']=(X_submission['Score1']*0.6+X_submission['Score2']*0.4).round(0)\n",
    "\n",
    "print(\"RMSE on testing set: regular predict = \", mean_squared_error(Y_test, Y_av4))\n",
    "\n",
    "submission = X_submission[['Id', 'Score']]\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]:\n",
    "    Y_av4 = (Y_test_review_pre * i + Y_test_regular_pre * (1-i)).round(0)\n",
    "    X_submission['Score']=(X_submission['Score1']*i+X_submission['Score2']*(1-i)).round(0)\n",
    "\n",
    "    print(\"RMSE on testing set: regular predict = \", mean_squared_error(Y_test, Y_av4))\n",
    "\n",
    "    submission = X_submission[['Id', 'Score']]\n",
    "    submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on testing set: regular predict =  1.820761683419962\n"
     ]
    }
   ],
   "source": [
    "# Predict using regular pd\n",
    "Y_test2 = model.predict(X_test_processed)\n",
    "X_submission['Score'] = model.predict(X_submission_processed)\n",
    "print(\"RMSE on testing set: regular predict = \", mean_squared_error(Y_test, Y_test2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = X_submission[['Id', 'Score']]\n",
    "submission.to_csv(\"submission.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
